{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f70849bb-1ced-480f-baaf-58bfc1009af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd35843f-c4b1-4f2a-a116-1535a1985b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUTUBE API KEY\n",
    "API_KEY = \"AIzaSyB9z4l6i2Fs-cGIkH1ssJMqBOKCIJY_ZLU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5fafdcc-caad-4b22-a700-961e9a3aeb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize YouTube API\n",
    "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8fa4d26-c1a7-4b35-819e-d433225ceace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Fetch Top Product Review Videos (Sorted by Views)\n",
    "def search_top_videos(query, max_results=50):\n",
    "    \"\"\"Fetches the most viewed product review videos.\"\"\"\n",
    "    request = youtube.search().list(\n",
    "        part=\"snippet\",\n",
    "        q=query,\n",
    "        type=\"video\",\n",
    "        maxResults=max_results,\n",
    "        order=\"viewCount\"  # Sort by highest views\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    videos = []\n",
    "    for item in response[\"items\"]:\n",
    "        videos.append({\n",
    "            \"video_id\": item[\"id\"][\"videoId\"],\n",
    "            \"video_title\": item[\"snippet\"][\"title\"],\n",
    "            \"channel_name\": item[\"snippet\"][\"channelTitle\"],\n",
    "            \"upload_date\": item[\"snippet\"][\"publishedAt\"]\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd434ca2-a8a8-4f9c-895d-be4f84f22f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total product review videos collected: 50\n"
     ]
    }
   ],
   "source": [
    "# Search for Most Viewed Product Review Videos\n",
    "df_videos = search_top_videos(\"best product reviews\", max_results=50)\n",
    "df_videos.to_csv(\"youtube_product_reviews_videos.csv\", index=False)\n",
    "print(f\"Total product review videos collected: {len(df_videos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccac9f7e-7fcf-40cf-940a-247f5df6ec85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total product review videos collected: 50\n"
     ]
    }
   ],
   "source": [
    "# Search for Most Viewed Product Review Videos\n",
    "df_videos = search_top_videos(\"best product reviews\", max_results=50)\n",
    "df_videos.to_csv(\"youtube_product_reviews_videos.csv\", index=False)\n",
    "print(f\"Total product review videos collected: {len(df_videos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daeb9a31-f0bd-4a8a-9e5e-ec6e35eeac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Fetch Comments from Each Video\n",
    "def get_video_comments(video_id, max_comments=1000, sleep_time=1):\n",
    "    \"\"\"Fetches comments from a video, prioritizing most engaged ones.\"\"\"\n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "    collected_comments = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet,replies\",\n",
    "                videoId=video_id,\n",
    "                maxResults=100,\n",
    "                pageToken=next_page_token,\n",
    "                order=\"relevance\",  # Prioritize most engaged comments\n",
    "                textFormat=\"plainText\"\n",
    "            )\n",
    "            response = request.execute()\n",
    "\n",
    "            for item in response.get(\"items\", []):\n",
    "                comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "                comments.append({\n",
    "                    \"video_id\": video_id,\n",
    "                    \"video_title\": video_title_dict.get(video_id, \"Unknown\"),\n",
    "                    \"comment_id\": item[\"id\"],\n",
    "                    \"comment_text\": comment[\"textDisplay\"],\n",
    "                    \"comment_author\": comment[\"authorDisplayName\"],\n",
    "                    \"comment_date\": comment[\"publishedAt\"],\n",
    "                    \"likes_on_comment\": comment[\"likeCount\"],\n",
    "                    \"replies_count\": item[\"snippet\"][\"totalReplyCount\"]\n",
    "                })\n",
    "                collected_comments += 1\n",
    "\n",
    "                # Fetch replies (if available)\n",
    "                if \"replies\" in item:\n",
    "                    for reply in item[\"replies\"][\"comments\"]:\n",
    "                        comments.append({\n",
    "                            \"video_id\": video_id,\n",
    "                            \"video_title\": video_title_dict.get(video_id, \"Unknown\"),\n",
    "                            \"comment_id\": reply[\"id\"],\n",
    "                            \"comment_text\": reply[\"snippet\"][\"textDisplay\"],\n",
    "                            \"comment_author\": reply[\"snippet\"][\"authorDisplayName\"],\n",
    "                            \"comment_date\": reply[\"snippet\"][\"publishedAt\"],\n",
    "                            \"likes_on_comment\": reply[\"snippet\"][\"likeCount\"],\n",
    "                            \"replies_count\": 0\n",
    "                        })\n",
    "                        collected_comments += 1\n",
    "\n",
    "            next_page_token = response.get(\"nextPageToken\")\n",
    "\n",
    "            if not next_page_token or collected_comments >= max_comments:\n",
    "                break\n",
    "\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching comments for {video_id}: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    return pd.DataFrame(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a293463-9104-4813-a642-b623163a2b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching comments for video 1/50: 7KHt0TshT2Q...\n",
      "Fetching comments for video 2/50: UHkq0-XKdZY...\n",
      "Fetching comments for video 3/50: ZZ_MBbmbgCY...\n",
      "Fetching comments for video 4/50: U68Zlppcr30...\n",
      "Fetching comments for video 5/50: XeML16BwHnw...\n",
      "Fetching comments for video 6/50: h359LRmMZMU...\n",
      "Fetching comments for video 7/50: DaJeg3f8jFk...\n",
      "Fetching comments for video 8/50: _3hQnHi5OEk...\n",
      "Fetching comments for video 9/50: WXggcRHXYAU...\n",
      "Fetching comments for video 10/50: VmrOxpNjJoA...\n",
      "Fetching comments for video 11/50: Z5k54Dd4OpY...\n",
      "Error fetching comments for Z5k54Dd4OpY: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet%2Creplies&videoId=Z5k54Dd4OpY&maxResults=100&order=relevance&textFormat=plainText&key=AIzaSyB9z4l6i2Fs-cGIkH1ssJMqBOKCIJY_ZLU&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter has disabled comments.', 'domain': 'youtube.commentThread', 'reason': 'commentsDisabled', 'location': 'videoId', 'locationType': 'parameter'}]\">\n",
      "Fetching comments for video 12/50: mBT6IuSRmss...\n",
      "Fetching comments for video 13/50: 4RcThoRG46c...\n",
      "Fetching comments for video 14/50: F5GRZblVx-g...\n",
      "Fetching comments for video 15/50: OjUogH3IPKs...\n",
      "Fetching comments for video 16/50: 6CsJZxfZsL0...\n",
      "Fetching comments for video 17/50: hrMQaau4S_0...\n",
      "Fetching comments for video 18/50: q3_kDiQb7lE...\n",
      "Fetching comments for video 19/50: lhkJiuBcP7E...\n",
      "Fetching comments for video 20/50: 7zR_5o6NvmE...\n",
      "Fetching comments for video 21/50: 7HIGdYy5of4...\n",
      "Fetching comments for video 22/50: r9vZItoI7yI...\n",
      "Fetching comments for video 23/50: QpbGctuHoMY...\n",
      "Fetching comments for video 24/50: 2csnNf-G9cI...\n",
      "Fetching comments for video 25/50: O9YnLFrM7Fs...\n",
      "Fetching comments for video 26/50: ZcZMGx15QBU...\n",
      "Fetching comments for video 27/50: S_523_3LV9I...\n",
      "Fetching comments for video 28/50: XXOX4z6uwXo...\n",
      "Fetching comments for video 29/50: e0kQ5WqjcU8...\n",
      "Fetching comments for video 30/50: sjpybsp0Vrg...\n",
      "Fetching comments for video 31/50: 7UmOzPopJNE...\n",
      "Fetching comments for video 32/50: H2-B2Lx3zXw...\n",
      "Fetching comments for video 33/50: l_GpHjng7OE...\n",
      "Fetching comments for video 34/50: alO7IFfuBTY...\n",
      "Fetching comments for video 35/50: KGcm0lo3Xng...\n",
      "Fetching comments for video 36/50: OyRmml3FkCc...\n",
      "Fetching comments for video 37/50: 8cIqLvJz8VM...\n",
      "Fetching comments for video 38/50: m0HNnQeWXvM...\n",
      "Fetching comments for video 39/50: hFWm5JEtShs...\n",
      "Fetching comments for video 40/50: GDeYsRqMj6s...\n",
      "Fetching comments for video 41/50: fb6fS0eujaI...\n",
      "Fetching comments for video 42/50: BPdz6BMj8EA...\n",
      "Fetching comments for video 43/50: j3ZCMcaAOVM...\n",
      "Fetching comments for video 44/50: RhhIwEQLbMw...\n",
      "Fetching comments for video 45/50: m8OU5J6OSt0...\n",
      "Fetching comments for video 46/50: odiYQObAS5c...\n",
      "Fetching comments for video 47/50: M1m0YTxBKqE...\n",
      "Fetching comments for video 48/50: KDfNwXXESiU...\n",
      "Fetching comments for video 49/50: zNBDDDIqlMk...\n",
      "Fetching comments for video 50/50: sQS6BAebPFk...\n"
     ]
    }
   ],
   "source": [
    "# Collect Comments from Top Videos\n",
    "all_comments = []\n",
    "video_title_dict = dict(zip(df_videos[\"video_id\"], df_videos[\"video_title\"]))\n",
    "\n",
    "for index, video_id in enumerate(df_videos[\"video_id\"]):\n",
    "    print(f\"Fetching comments for video {index + 1}/{len(df_videos)}: {video_id}...\")\n",
    "    df_video_comments = get_video_comments(video_id, max_comments=2000)\n",
    "    if not df_video_comments.empty:\n",
    "        all_comments.append(df_video_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2aa223c-7b77-4f41-b77a-1b94fe10c9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total comments collected: 64558\n"
     ]
    }
   ],
   "source": [
    "# Save All Comments to CSV\n",
    "df_all_comments = pd.concat(all_comments, ignore_index=True)\n",
    "df_all_comments.to_csv(\"youtube_product_review_comments.csv\", index=False)\n",
    "\n",
    "print(f\"Total comments collected: {len(df_all_comments)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dd8658-dc5e-4ff1-a9fb-3bdca87b5be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
